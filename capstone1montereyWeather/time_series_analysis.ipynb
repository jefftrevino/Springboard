{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Analysis Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My notes on DataCamp's [Time Series Analysis in Python](https://campus.datacamp.com/courses/introduction-to-time-series-analysis-in-python/) course (1-5), notes on [Machine Learning Mastery](machinelearningmastery.com) tutorials (6-8), and my notes on exponential smoothing with code ported from R (5):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents\n",
    "1. [Understanding the Dickey-Fuller Test](#dftest)\n",
    "2. [Auto-Regressive (AR) Models](#ar)\n",
    "3. [Moving Average (MA) and ARMA Models](#ma)\n",
    "4. [Cointegration Models](#coint)\n",
    "5. [Case Study: Climate Change in NYC](#nyc)\n",
    "6. [ARIMA Models](#arima)\n",
    "7. [SARIMA Models](#sarima)\n",
    "8. [ARCH and GARCH Models](#garch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dftest'></a>\n",
    "### 1. Understanding the Dickey-Fuller Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a random walk, the current value is equal to the last value plus some noise:\n",
    "\n",
    "\\begin{equation}\n",
    "y_t = ay_{t-1} + \\epsilon_t\n",
    "\\end{equation}\n",
    "\n",
    "If the value of $a$ is 1, then each term is equal to the last, except for the added error. The random walk is \"integrated of order 1,\" in that we must difference it once to get a stationary series. (A stationary series does not change its mean or variance over time.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the difference between two points in time is due completely to the added error, there should be no contributing slope component in the difference between two values:\n",
    "\n",
    "\\begin{equation}\n",
    "y_t - y_{t-1} = (\\phi - 1)y_{t-1} + \\epsilon_t\n",
    "\\end{equation}\n",
    "\n",
    "That is, mathematically, if there's a unit root is present in the current value formula ($a=1$), when we check the correlation between the difference series and the lagged series, the slope (correlation) coefficient of the lagged series ($\\phi - 1$) should be zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is what the Dickey-Fuller Test investigates: the Dickey-Fuller Test correlates a series' difference against its lag. If the correlation coefficient (slope) is 0 or very close to 0, the difference is just the noise and the current value series is a random walk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ar'></a>\n",
    "### 2. Auto-Regressive (AR) Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In an AR model of order 1 (AR(1)), today's value is a mean plus a fraction of yesterday's value plus noise:\n",
    "\n",
    "\\begin{equation}\n",
    "y_t = \\mu + \\phi y_{t-1} + \\epsilon_t\n",
    "\\end{equation}\n",
    "\n",
    "An AR(1) series can be stationary if $-1 \\lt \\phi \\lt 1$. A positive value for $\\phi$ means the series will behave a bit like a random walk and exhibit momentum, while a negative value means that values will alternate sign and exhibit mean reversion (and the series looks a bit like a waveform).\n",
    "\n",
    "Intuitively: if $\\phi$ is negative, the current value is the flipped sign of the last value, and the path of the series alternates its direction every other value. A positive $\\phi$ doesn't result in this alternation.\n",
    "\n",
    "The autocorrelation function of an AR(1) series decays exponentially: the lag(1) series will have autocorrelation $\\phi$, lag(2) $\\phi^2$, lag(3) $\\phi^3$, and lag(n) $\\phi^n$. A negative value just reverses the sign of the autocorrelation at each lag: the comparison alternates between same and opposite signs (see intuition above). Describing the current value with two values back is AR(2), three back AR(3), n back AR(n)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulating an AR process: general example\n",
    "from statsmodels.tsa.arima_process import ArmaProcess\n",
    "ar = np.array([1, -0.9]) # zero-lag coefficient of 1, phi value of 0.9 (! it's the opposite because signal processing)\n",
    "ma = np.array([1])\n",
    "AR_object = ArmaProcess(ar, ma)\n",
    "simulated_data = AR_object.generate_sample(nsample=1000)\n",
    "plt.plot(simulated_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulating an AR process: specific example with plot\n",
    "# import the module for simulating data\n",
    "from statsmodels.tsa.arima_process import ArmaProcess\n",
    "\n",
    "# Plot 1: AR parameter = +0.9\n",
    "plt.subplot(2,1,1)\n",
    "ar1 = np.array([1, -0.9])\n",
    "ma1 = np.array([1])\n",
    "AR_object1 = ArmaProcess(ar1, ma1)\n",
    "simulated_data_1 = AR_object1.generate_sample(nsample=1000)\n",
    "plt.plot(simulated_data_1)\n",
    "\n",
    "# Plot 2: AR parameter = -0.9\n",
    "plt.subplot(2,1,2)\n",
    "ar2 = np.array([1, 0.9])\n",
    "ma2 = np.array([1])\n",
    "AR_object2 = ArmaProcess(ar2, ma2)\n",
    "simulated_data_2 = AR_object2.generate_sample(nsample=1000)\n",
    "plt.plot(simulated_data_2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimating and Forecasting an AR Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how to estimate the some data set's $\\phi$, assuming an AR(1) model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the ARMA module from statsmodels\n",
    "from statsmodels.tsa.arima_model import ARMA\n",
    "\n",
    "# Fit an AR(1) model to the first simulated data\n",
    "mod = ARMA(simulated_data_1, order=(1,0)) # fit to AR(1) model\n",
    "res = mod.fit()\n",
    "\n",
    "# Print out summary information on the fit\n",
    "print(res.summary())\n",
    "\n",
    "# Print out the estimate for the constant and for phi\n",
    "print(\"When the true phi=0.9, the estimate of phi (and the constant) are:\")\n",
    "print(res.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's how to forecast a particular date range with an AR(1) model using the `predict()` and `plot_predict()` methods. \"In-sample\" forecasting guesses one value after the existing data, while \"out-of-sample\" forecasts some values into the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the ARMA module from statsmodels\n",
    "from statsmodels.tsa.arima_model import ARMA\n",
    "\n",
    "# Forecast the first AR(1) model\n",
    "mod = ARMA(simulated_data_1, order=(1,0))\n",
    "res = mod.fit()\n",
    "res.plot_predict(start=990, end=1010) # point 990 to point 1010 out of a 1,000 value series\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it's tough to tell the difference between a random walk and a time series that mean reverts a little bit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choosing the Right Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do you know the best order $p$ for an AR($p$) model? The partial autocorrelation function (PACF) and the information criteria help you choose the order of your model.\n",
    "\n",
    "The PACF measures the incremental benefit of adding another lag to the model function. `plot_pacf()` works like `plot_acf()`: one series argument and two kwargs, lag and alpha. The number of lags significantly (out of the blue signficance band you choose with alpha) different than zero tells you the order of the model.\n",
    "\n",
    "Information Criteria prevents overfitting by assessing a penalty for more model parameters. Two goodness-of-fit measures:\n",
    "\n",
    "1. AIC( Akaike Information Criterion) `result.aic`\n",
    "2. BIC (Bayesian Information Criterion) `result.bic`\n",
    "\n",
    "In practice, fit several models and then check out the BIC for each. Choose the model with the lowest value for the best fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how to plot the PACF for a series:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the modules for simulating data and for plotting the PACF\n",
    "from statsmodels.tsa.arima_process import ArmaProcess\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "\n",
    "# Simulate AR(1) with phi=+0.6\n",
    "ma = np.array([1])\n",
    "ar = np.array([1, -0.6])\n",
    "AR_object = ArmaProcess(ar, ma)\n",
    "simulated_data_1 = AR_object.generate_sample(nsample=5000)\n",
    "\n",
    "# Plot PACF for AR(1)\n",
    "plot_pacf(simulated_data_1, lags=20)\n",
    "plt.show()\n",
    "\n",
    "# Simulate AR(2) with phi1=+0.6, phi2=+0.3\n",
    "ma = np.array([1])\n",
    "ar = np.array([1, -0.6, -0.3])\n",
    "AR_object = ArmaProcess(ar, ma)\n",
    "simulated_data_2 = AR_object.generate_sample(nsample=5000)\n",
    "\n",
    "# Plot PACF for AR(2)\n",
    "plot_pacf(simulated_data_2, lags=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how to plot the BIC as a function of model order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the module for estimating an ARMA model\n",
    "from statsmodels.tsa.arima_model import ARMA\n",
    "\n",
    "# Fit the data to an AR(p) for p = 0,...,6 , and save the BIC\n",
    "BIC = np.zeros(7)\n",
    "for p in range(7):\n",
    "    mod = ARMA(simulated_data_2, order=(p,0))\n",
    "    res = mod.fit()\n",
    "# Save BIC for AR(p)    \n",
    "    BIC[p] = res.bic\n",
    "    \n",
    "# Plot the BIC as a function of p\n",
    "plt.plot(range(1,7), BIC[1:7], marker='o')\n",
    "plt.xlabel('Order of AR Model')\n",
    "plt.ylabel('Bayesian Information Criterion')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ma'></a>\n",
    "### 3. Moving Average (MA) and ARMA Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In an MA(1) model (moving average model of order 1), today's value is a mean pluse noise plus a fraction theta of yesterday's noise:\n",
    "\n",
    "\\begin{equation}\n",
    "y_t = \\mu + \\epsilon + \\theta \\epsilon_{t-1}\n",
    "\\end{equation}\n",
    "\n",
    "This is of order 1, because there's one lagged value in the equation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If $\\theta$ is 0, the process is white noise shifted by a mean. MA models are stationary for all values of theta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If \\theta is negative, then a positive value last period means the next value is likely to be negative; a positive value two values might not have any effect two values later.\n",
    "\n",
    "lag(1) autocorrelation for MA models is not $\\theta$ but $\\theta/(1+\\theta)^2$. When $\\theta$ is negative, lag(1) autocorrelation is negative. When $\\theta$ is positive, lag(1) autocorrelation is positive. An MA(n) has no autocorrelation beyond lag(n)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how to simulate an MA process:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the module for simulating data\n",
    "from statsmodels.tsa.arima_process import ArmaProcess\n",
    "\n",
    "# Plot 1: MA parameter = -0.9\n",
    "plt.subplot(2,1,1)\n",
    "ar1 = np.array([1])\n",
    "ma1 = np.array([1, -.9])\n",
    "MA_object1 = ArmaProcess(ar1, ma1)\n",
    "simulated_data_1 = MA_object1.generate_sample(nsample=1000)\n",
    "plt.plot(simulated_data_1)\n",
    "\n",
    "# Plot 2: MA parameter = +0.9\n",
    "plt.subplot(2,1,2)\n",
    "ar2 = np.array([1])\n",
    "ma2 = np.array([1, 0.9])\n",
    "MA_object2 = ArmaProcess(ar2, ma2)\n",
    "simulated_data_2 = MA_object2.generate_sample(nsample=1000)\n",
    "plt.plot(simulated_data_2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's how to compute the autocorrelation for an MA series (as before):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the plot_acf module from statsmodels\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "# Plot 1: MA parameter = -0.9\n",
    "plot_acf(simulated_data_1, lags=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estimating and Forecasting an MA Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just use statsmodel's `ARMA` class as with an AR model, but pass in `order=(0,1)` in place of `order=(1,0)` for an MA model. You can forecast a single value after data, and then one more value after that, after which all values will be the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ARMA Models\n",
    "\n",
    "In an AR model, the current value has to do with n previous values. In an MA model, the current value has to do with n previous noise components. In an ARMA model, the current value has to do with both past values and past noise components.\n",
    "\n",
    "In an ARMA(1, 1) model, the current value is equal to a mean plus some fraction $\\phi$ of the last value plus some noise component plus some fraction $\\theta$ of the last noise component.\n",
    "\n",
    "\\begin{equation}\n",
    "y_t = \\mu + \\phi y_{t-1} + \\epsilon + \\theta \\epsilon_{t-1}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's possible to convert an ARMA  model of order n into an AR model of order inifinity or an MA model of order infinity by substitution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Neat Trick:* It' useful to find the indices of missing data by subtracting the index from a complete range:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Everything\n",
    "set_everything = set(range(391))\n",
    "\n",
    "# The intraday index as a set\n",
    "set_intraday = set(intraday.index)\n",
    "\n",
    "# Calculate the difference\n",
    "set_missing = set_everything - set_intraday\n",
    "\n",
    "# Print the difference\n",
    "print(\"Missing rows: \", set_missing)\n",
    "\n",
    "# reindex with forward fill to replace missing values\n",
    "intraday = intraday.reindex(range(391), method='ffill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforming a numeric index into a datetime index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas has a `date_range` method. Make a date range and set it as the index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From previous step\n",
    "intraday = intraday.reindex(range(391), method='ffill')\n",
    "\n",
    "# Change the index to the intraday times\n",
    "intraday.index = pd.date_range(start='2017-09-01 9:30', end='2017-09-01 16:00', freq='1min')\n",
    "\n",
    "# Plot the intraday time series\n",
    "intraday.plot(grid=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying an MA Model\n",
    "\n",
    "If you see no autocorrelations at lags higher than n, you should fit an MA(n) model to the data. Compute the difference series using `pct_change()` and then fit an MA model to the difference series, remembering to use `drop_na()` to get rid of the first row's `NaN` (because differences)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import plot_acf and ARMA modules from statsmodels\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.tsa.arima_model import ARMA\n",
    "\n",
    "# Compute returns from prices and drop the NaN\n",
    "returns = intraday.pct_change()\n",
    "returns = returns.dropna()\n",
    "\n",
    "# Plot ACF of returns with lags up to 60 minutes\n",
    "plot_acf(returns, lags=60)\n",
    "plt.show()\n",
    "\n",
    "# Fit the data to an MA(1) model\n",
    "mod = ARMA(returns, order=(0,1))\n",
    "res = mod.fit()\n",
    "print(res.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulating an AR(1) model as an MR($\\infty$) Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An AR(1) model is the same as an MR($\\infty$) model:\n",
    "\n",
    "\\begin{equation}\n",
    "y_t = \\mu + \\phi y_{t-1} + \\epsilon\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "y_t = \\mu + \\sum_{i=1}^{\\infty} \\phi^i \\epsilon_{t-i}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a simulation of an AR(1) model with $\\phi$=0.8 as an MR($\\infty$) model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the modules for simulating data and plotting the ACF\n",
    "from statsmodels.tsa.arima_process import ArmaProcess\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "\n",
    "# Build a list MA parameters\n",
    "ma = [0.8**i for i in range(30)]\n",
    "\n",
    "# Simulate the MA(30) model\n",
    "ar = np.array([1])\n",
    "AR_object = ArmaProcess(ar, ma)\n",
    "simulated_data = AR_object.generate_sample(nsample=5000)\n",
    "\n",
    "# Plot the ACF\n",
    "plot_acf(simulated_data, lags=30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='coint'></a>\n",
    "### 4. Cointegration Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even if two series are each independently a random walk, it's still possible that their linear combination isn't a random walk and is therefore forecastable. For example: the distance between a dog and its walking owner is mean reverting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking Two Series for Cointegration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have two series $P_t$ and $Q_t$ and want to check for their cointegration,\n",
    "1. Regress $P_t$ on $Q_t$ to get a slope (correlation coefficient) $c$.\n",
    "2. Test the linear combination of the two series, $P_t - cQ_t$, for random walkness using the Augmented Dickey Fuller test.\n",
    "\n",
    "In Python this looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.statstools import coint\n",
    "coint(P, Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be helpful to plot the two series separately, as well as their difference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the prices separately\n",
    "plt.subplot(2,1,1)\n",
    "plt.plot(7.25*HO, label='Heating Oil')\n",
    "plt.plot(NG, label='Natural Gas')\n",
    "plt.legend(loc='best', fontsize='small')\n",
    "\n",
    "# Plot the spread\n",
    "plt.subplot(2,1,2)\n",
    "plt.plot(7.25*HO-NG, label='Spread')\n",
    "plt.legend(loc='best', fontsize='small')\n",
    "plt.axhline(y=0, linestyle='--', color='k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the ADF test to each series separately, and then to their difference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the adfuller module from statsmodels\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Compute the ADF for HO and NG\n",
    "result_HO = adfuller(HO['Close'])\n",
    "print(\"The p-value for the ADF test on HO is \", result_HO[1])\n",
    "result_NG = adfuller(NG['Close'])\n",
    "print(\"The p-value for the ADF test on NG is \", result_NG[1])\n",
    "\n",
    "# Compute the ADF of the spread\n",
    "result_spread = adfuller(7.25 * HO['Close'] - NG['Close'])\n",
    "print(\"The p-value for the ADF test on the spread is \", result_spread[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here's an example of the two-step process from above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the statsmodels module for regression and the adfuller function\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Regress BTC on ETH\n",
    "ETH = sm.add_constant(ETH) # add column of 1s to ETH to get a y-intercept\n",
    "result = sm.OLS(BTC,ETH).fit()\n",
    "\n",
    "# Compute ADF\n",
    "b = result.params[1]\n",
    "adf_stats = adfuller(BTC['Price'] - b*ETH['Price'])\n",
    "print(\"The p-value for the ADF test is \", adf_stats[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='nyc'></a>\n",
    "### 5. Case Study: Climate Change in NYC and ARIMA Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average annual temperature data act like a random walk with drift (ADF test result is 0.58):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the adfuller function from the statsmodels module\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Convert the index to a datetime object\n",
    "temp_NY.index = pd.to_datetime(temp_NY.index, format='%Y')\n",
    "\n",
    "# Plot average temperatures\n",
    "temp_NY.plot()\n",
    "plt.show()\n",
    "\n",
    "# Compute and print ADF p-value\n",
    "result = adfuller(temp_NY['TAVG'])\n",
    "print(\"The p-value for the ADF test is \", result[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make a random walk with drift stationary, take its first difference. Then we'll compute the ACF and the PACF to get guidance on which model to use. We see lag(1) as the only significant value, and it's negative. This means we should model this as an MA(1) model with a negative $\\theta$ value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the modules for plotting the sample ACF and PACF\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "\n",
    "# Take first difference of the temperature Series\n",
    "chg_temp = temp_NY.diff()\n",
    "chg_temp = chg_temp.dropna()\n",
    "\n",
    "# Plot the ACF and PACF on the same page\n",
    "fig, axes = plt.subplots(2,1)\n",
    "\n",
    "# Plot the ACF\n",
    "plot_acf(chg_temp, lags=20, ax=axes[0])\n",
    "\n",
    "# Plot the PACF\n",
    "plot_pacf(chg_temp, lags=20, ax=axes[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit the data to AR(1), AR(2), and ARMA(1,1) models to see which one has the lowest Akaike Information Criterion (AIC) value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the module for estimating an ARMA model\n",
    "from statsmodels.tsa.arima_model import ARMA\n",
    "\n",
    "# Fit the data to an AR(1) model and print AIC:\n",
    "mod_ar1 = ARMA(chg_temp, order=(1, 0))\n",
    "res_ar1 = mod_ar1.fit()\n",
    "print(\"The AIC for an AR(1) is: \", res_ar1.aic)\n",
    "\n",
    "# Fit the data to an AR(2) model and print AIC:\n",
    "mod_ar2 = ARMA(chg_temp, order=(2, 0))\n",
    "res_ar2 = mod_ar2.fit()\n",
    "print(\"The AIC for an AR(2) is: \", res_ar2.aic)\n",
    "\n",
    "# Fit the data to an ARMA(1,1) model and print AIC:\n",
    "mod_arma11 = ARMA(chg_temp, order=(1,1))\n",
    "res_arma11 = mod_arma11.fit()\n",
    "print(\"The AIC for an ARMA(1,1) is: \", res_arma11.aic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ARMA(1,1) model has the lowest AIC value of the three, which means it fits the data the best of the three."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ARIMA Models\n",
    "\n",
    "Using an ARIMA model on the data is identical to using an ARMA model on the data's differences and then taking cumulative sums of temperature change to forecast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To plot predictions using an ARMA(1,1) model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the ARIMA module from statsmodels\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "\n",
    "# Forecast temperatures using an ARIMA(1,1,1) model\n",
    "mod = ARIMA(temp_NY, order=(1,1,1)) #pdq d is 1 because we differenced once\n",
    "res = mod.fit()\n",
    "\n",
    "# Plot the original series and the forecasted series\n",
    "res.plot_predict(start='1872-01-01', end='2046-01-01')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*\"According to the model, the temperature in NYC is expected to be about 0.6 degrees higher in 30 years (almost entirely due to the trend), but the 95% confidence interval around that is over 5 degrees.\"*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More complex topics to explore:\n",
    "- GARCH Models\n",
    "- Nonlinear Models\n",
    "- Multivariate Time Series Models\n",
    "- Regime Switching Models\n",
    "- State Space Models and Kalman Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. ARIMA Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ARIMA adds integration to ARMA. Auto-Regressive Integrated Moving Average model. To recap what that means from above:\n",
    "\n",
    "- AR: Autoregression. A model that uses the dependent relationship between an observation and some number of lagged observations.\n",
    "\n",
    "- I: Integrated. The use of differencing of raw observations (e.g. subtracting an observation from an observation at the previous time step) in order to make the time series stationary.\n",
    "\n",
    "- MA: Moving Average. A model that uses the dependency between an observation and a residual error from a moving average model applied to lagged observations.\n",
    "\n",
    "The ARIMA model takes these three dimensions as three parameters:\n",
    "\n",
    "- p: The number of lag observations included in the model, also called the lag order.\n",
    "- d: The number of times that the raw observations are differenced, also called the degree of differencing.\n",
    "- q: The size of the moving average window, also called the order of moving average.\n",
    "\n",
    "If q is 0, you get an ARMA model. If p and q are zero, you get an MA model. If d and q are 0, you get an AR model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, if we want to make an ARIMA model of some random-walk looking monthly shampoo sales data,\n",
    "\n",
    "- p=5, because an autocorrelation plot of the values shows significant values for lags through 5.\n",
    "- d=1, because you difference a random walk once to make it stationary\n",
    "- q=0, because ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = read_csv('shampoo-sales.csv', header=0, parse_dates=[0], index_col=0, squeeze=True, date_parser=parser)\n",
    "# fit model\n",
    "model = ARIMA(series, order=(5,1,0))\n",
    "model_fit = model.fit(disp=0)\n",
    "print(model_fit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, plot the residuals to see if there's trend information the models' missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot residual errors\n",
    "residuals = DataFrame(model_fit.resid)\n",
    "residuals.plot()\n",
    "pyplot.show()\n",
    "residuals.plot(kind='kde')\n",
    "pyplot.show()\n",
    "print(residuals.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows a bias in the prediction: the mean of the residuals is -5, not 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sarima'></a>\n",
    "### 7. SARIMA Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ARIMA can handle data with a trend, but it doesn't deal with seasonal components. ARIMA expects data with a trend only. If data have a seasonal component, seasonal differencing needs to be performed before analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SARIMA adds a separate ARIMA model for the seasonal component. That means four new parameters:\n",
    "\n",
    "- pdq as above for the seasonal component's ARIMA model\n",
    "- a fourth parameter specifying the period of the seasonal component\n",
    "\n",
    "Pass in the trend and seasonal parameters as two 3- and 4-value tuples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.sarimax import SARIMAX\n",
    "\n",
    "# define model configuration\n",
    "my_order = (1, 1, 1)\n",
    "my_seasonal_order = (1, 1, 1, 12)\n",
    "# define model\n",
    "model = SARIMAX(data, order=my_order, seasonal_order=my_seasonal_order, ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting and prediction work as above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "model_fit = model.fit()\n",
    "# one step forecast\n",
    "yhat = model_fit.forecast()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='garch'></a>\n",
    "### 8. ARCH and GARCH Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the variance is shifting over time in some systematic way (data exhibit heteroskedasticity), AR, MA, ARMA, ARIMA, and SARIMA models will not model the data very well, enter ARCH (Engle, 1982):\n",
    "\n",
    "__A__ Auto-\n",
    "\n",
    "__R__ Regressive\n",
    "\n",
    "__C__ Conditional\n",
    "\n",
    "__H__ Heteroskedasticity\n",
    "\n",
    "...to model the variance of the variance over time.\n",
    "\n",
    "It models variance as a function of residuals from a zero mean process. $q$ is the number of lag-squared residual errors to include in the model. (It's called $p$ sometimes, but you need to call it $q$ for the next bit on GARCH to make any sense.)\n",
    "\n",
    "ARCH expects a stationary series that doesn't have a trend or seasonal component. So you need to fit one of the above models first, and then run the residuals through ARCH."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GARCH is ARCH with a moving average. A GARCH model has two parameters:\n",
    "\n",
    "- $p$ past variances in the model\n",
    "\n",
    "- $q$ past residual errors in the model\n",
    "\n",
    "For example, a GARCH model of order 1 (GARCH(1,1)) models current variance as a mean plus a fraction of the square of the lag noise plus a fraction of the square of the lag variance:\n",
    "\n",
    "\\begin{equation}\n",
    "\\sigma^2 = \\mu + \\phi \\epsilon_{t-1}^2 + \\theta \\sigma_{t-1}^2\n",
    "\\end{equation}\n",
    "\n",
    "Just as ARMA subsumes AR and MA models, GARCH subsumes ARCH. A GARCH(0,q) model is an ARCH(q) model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Configuring ARCH and GARCH Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You want to approach the variance of the series like you approached the difference above: have a look at the ACF and PACF of the variance.\n",
    "\n",
    "1. Subtract the mean from each value in the series.\n",
    "2. Square the result.\n",
    "3. Plot the ACF and PACF.\n",
    "4. Interpret these plots like you did above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ARCH and GARCH in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the [arch](https://github.com/bashtage/arch) package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arch import arch_model\n",
    "am = arch_model(data)\n",
    "res = am.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can model a linear increase in variance using a draw from a Gaussian distribution with an expanding standard deviation (increasingly spastic variation about a mean of 0):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset\n",
    "data = [gauss(0, i*0.01) for i in range(1,100+1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The squared data show significant autocorrelation out to about 15 lags:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "squared_data = [x**2 for x in data]\n",
    "# create acf plot\n",
    "plot_acf(squared_data)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15 becomes the value passed into the ARCH model on configuration. We fit the model and then use it to forecast. This code defines the model and forecasts the variance of the last ten timesteps in the dataset. It plots the actual variance against the forecast variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = arch_model(data, mean='Zero', vol='ARCH', p=15)\n",
    "# fit model\n",
    "model_fit = model.fit()\n",
    "# forecast the test set\n",
    "yhat = model_fit.forecast(horizon=10)\n",
    "# plot the actual variance\n",
    "var = [i*0.01 for i in range(0,100)]\n",
    "pyplot.plot(var[-n_test:])\n",
    "# plot forecast variance\n",
    "pyplot.plot(yhat.variance.values[-1, :])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting a GARCH model works similarly, but you configure two parameters now and specify `vol='GARCH'`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "model = arch_model(train, mean='Zero', vol='GARCH', p=15, q=15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
